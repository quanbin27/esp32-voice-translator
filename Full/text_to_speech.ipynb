{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech Using Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperperemeter Class\n",
    "\n",
    "**he Hyperparams class contains all the necessary parameters for configuring the text-to-speech model. These parameters include file paths, text and sound transformation settings, model architecture details, and training configurations.**\n",
    "\n",
    "* File Paths: Paths for input CSV files, waveform data, saving models, and logging.\n",
    "* Text Transformations: List of symbols used for text preprocessing and their mapping.\n",
    "* Sound Transformations: Sample rate, FFT parameters, mel frequency bins, decibel scaling, etc.\n",
    "* Model Parameters: Embedding sizes, kernel sizes, and other architecture-related settings.\n",
    "* Training Parameters: Batch size, gradient clipping value, learning rate, and steps for logging, testing, and saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:53:50.6708Z",
     "iopub.status.busy": "2025-03-18T03:53:50.670477Z",
     "iopub.status.idle": "2025-03-18T03:53:50.684884Z",
     "shell.execute_reply": "2025-03-18T03:53:50.684059Z",
     "shell.execute_reply.started": "2025-03-18T03:53:50.670768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EOS', ' ', '!', ',', '-', '.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'è', 'é', 'ê', 'ü', '’', '“', '”']\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "class Hyperparams:\n",
    "  seed = 42\n",
    "\n",
    "  # csv_path = \"/kaggle/input/ljspeech-meta/metadata.csv\"\n",
    "  # wav_path = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs\"\n",
    "  # save_path = \"/kaggle/working/param\"  \n",
    "  # log_path = \"/kaggle/working/train_logs\"\n",
    "  \n",
    "  # save_name = \"SimpleTransfromerTTS.pt\"\n",
    "\n",
    "  # Text transformations params\n",
    "  symbols = [\n",
    "    'EOS', ' ', '!', ',', '-', '.', \\\n",
    "    ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', \\\n",
    "    'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
    "    'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', \\\n",
    "    'â', 'è', 'é', 'ê', 'ü', '’', '“', '”' \\\n",
    "  ]\n",
    "  \n",
    "  # Sounds transformations params\n",
    "  sr = 22050\n",
    "  n_fft = 2048\n",
    "  n_stft = int((n_fft//2) + 1)\n",
    "  \n",
    "  frame_shift = 0.0125 # seconds\n",
    "  hop_length = int(n_fft/8.0)\n",
    "  \n",
    "  frame_length = 0.05 # seconds  \n",
    "  win_length = int(n_fft/2.0)\n",
    "  \n",
    "  mel_freq = 128\n",
    "  max_mel_time = 1024\n",
    "  \n",
    "  max_db = 100  \n",
    "  scale_db = 10\n",
    "  ref = 4.0\n",
    "  power = 2.0\n",
    "  norm_db = 10 \n",
    "  ampl_multiplier = 10.0\n",
    "  ampl_amin = 1e-10\n",
    "  db_multiplier = 1.0\n",
    "  ampl_ref = 1.0\n",
    "  ampl_power = 1.0\n",
    "\n",
    "  # Model params\n",
    "  text_num_embeddings = 2*len(symbols)  \n",
    "  embedding_size = 256\n",
    "  encoder_embedding_size = 512 \n",
    "\n",
    "  dim_feedforward = 1024\n",
    "  postnet_embedding_size = 1024\n",
    "\n",
    "  encoder_kernel_size = 3\n",
    "  postnet_kernel_size = 5\n",
    "\n",
    "  # Other\n",
    "  batch_size = 32\n",
    "  grad_clip = 1.0\n",
    "  lr = 2.0 * 1e-4\n",
    "  r_gate = 1.0\n",
    "\n",
    "  step_print = 1000\n",
    "  step_test = 8000\n",
    "  step_save = 8000\n",
    "\n",
    "hp = Hyperparams()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(hp.symbols)\n",
    "  print(len(hp.symbols))\n",
    "    \n",
    "    \n",
    "hp = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask from Sequence Lengths Function\n",
    "\n",
    "**This function creates a mask tensor for a batch of sequences with different lengths.**\n",
    "\n",
    "* **Purpose**: To create a mask that identifies valid positions within each sequence in a batch, useful for padding sequences in deep learning models.\n",
    "* **Input**: A tensor containing sequence lengths and the maximum sequence length.\n",
    "* **Output**: A boolean mask tensor where positions with valid data are marked as True and padding positions are False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:53:55.885574Z",
     "iopub.status.busy": "2025-03-18T03:53:55.884942Z",
     "iopub.status.idle": "2025-03-18T03:53:59.390013Z",
     "shell.execute_reply": "2025-03-18T03:53:59.389331Z",
     "shell.execute_reply.started": "2025-03-18T03:53:55.885545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "symbol_to_id = {\n",
    "  s: i for i, s in enumerate(hp.symbols)\n",
    "}\n",
    "\n",
    "def mask_from_seq_lengths(\n",
    "    sequence_lengths: torch.Tensor, \n",
    "    max_length: int\n",
    ") -> torch.BoolTensor:\n",
    "    \"\"\"\n",
    "    our input was `[2, 2, 3]`, with a `max_length` of 4, we'd return\n",
    "    `[[1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]]`.\n",
    "    \"\"\"\n",
    "    # (batch_size, max_length)\n",
    "    ones = sequence_lengths.new_ones(sequence_lengths.size(0), max_length)\n",
    "    range_tensor = ones.cumsum(dim=1)\n",
    "    return sequence_lengths.unsqueeze(1) >= range_tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Sequence Conversion\n",
    "\n",
    "* **Purpose**: To convert text into a format suitable for input into a neural network.\n",
    "* **Input**: A string of text.\n",
    "* **Output**: A tensor of integer IDs corresponding to the symbols in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T03:57:18.026417Z",
     "iopub.status.busy": "2025-03-12T03:57:18.025569Z",
     "iopub.status.idle": "2025-03-12T03:57:18.059283Z",
     "shell.execute_reply": "2025-03-12T03:57:18.05854Z",
     "shell.execute_reply.started": "2025-03-12T03:57:18.026381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 12, 19, 19, 22,  3,  1, 30, 22, 25, 19, 11,  0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "symbol_to_id = {\n",
    "    \n",
    "  s: i for i, s in enumerate(hp.symbols)\n",
    "}\n",
    "\n",
    "def text_to_seq(text):\n",
    "  text = text.lower()\n",
    "  seq = []\n",
    "  for s in text:\n",
    "    _id = symbol_to_id.get(s, None)\n",
    "    if _id is not None:\n",
    "      seq.append(_id)\n",
    "\n",
    "  seq.append(symbol_to_id[\"EOS\"])\n",
    "\n",
    "  return torch.IntTensor(seq)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(text_to_seq(\"Hello, World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing\n",
    "\n",
    "**These functions handle the conversion between waveform and mel spectrogram, including normalization and denormalization.**\n",
    "\n",
    "1. **Spectrogram Transformation**: Converts waveform to spectrogram.\n",
    "2. **Mel Scale Transformation**: Converts spectrogram to mel spectrogram.\n",
    "3. **Inverse Mel Scale Transformation**: Converts mel spectrogram back to spectrogram.\n",
    "4. **Griffin-Lim Transformation**: Converts spectrogram back to waveform.\n",
    "5. **Normalization**: Normalizes mel spectrogram to a specific range.\n",
    "6. **Denormalization**: Converts normalized mel spectrogram back to original scale.\n",
    "7. **Power to dB Conversion**: Converts mel spectrogram from power to decibel scale.\n",
    "8. **dB to Power Conversion**: Converts mel spectrogram from decibel to power scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True nếu GPU hoạt động\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:54:19.098686Z",
     "iopub.status.busy": "2025-03-18T03:54:19.097898Z",
     "iopub.status.idle": "2025-03-18T03:54:21.044495Z",
     "shell.execute_reply": "2025-03-18T03:54:21.04367Z",
     "shell.execute_reply.started": "2025-03-18T03:54:19.098658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.functional import spectrogram\n",
    "\n",
    "\n",
    "spec_transform = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=hp.n_fft, \n",
    "    win_length=hp.win_length,\n",
    "    hop_length=hp.hop_length,\n",
    "    power=hp.power\n",
    ")\n",
    "\n",
    "\n",
    "mel_scale_transform = torchaudio.transforms.MelScale(\n",
    "  n_mels=hp.mel_freq, \n",
    "  sample_rate=hp.sr, \n",
    "  n_stft=hp.n_stft\n",
    ")\n",
    "\n",
    "\n",
    "mel_inverse_transform = torchaudio.transforms.InverseMelScale(\n",
    "  n_mels=hp.mel_freq, \n",
    "  sample_rate=hp.sr, \n",
    "  n_stft=hp.n_stft\n",
    ").cuda()\n",
    "\n",
    "\n",
    "griffnlim_transform = torchaudio.transforms.GriffinLim(\n",
    "    n_fft=hp.n_fft,\n",
    "    win_length=hp.win_length,\n",
    "    hop_length=hp.hop_length\n",
    ").cuda()\n",
    "\n",
    "\n",
    "def norm_mel_spec_db(mel_spec):  \n",
    "  mel_spec = ((2.0*mel_spec - hp.min_level_db) / (hp.max_db/hp.norm_db)) - 1.0\n",
    "  mel_spec = torch.clip(mel_spec, -hp.ref*hp.norm_db, hp.ref*hp.norm_db)\n",
    "  return mel_spec\n",
    "\n",
    "\n",
    "def denorm_mel_spec_db(mel_spec):\n",
    "  mel_spec = (((1.0 + mel_spec) * (hp.max_db/hp.norm_db)) + hp.min_level_db) / 2.0 \n",
    "  return mel_spec\n",
    "\n",
    "\n",
    "def pow_to_db_mel_spec(mel_spec):\n",
    "  mel_spec = torchaudio.functional.amplitude_to_DB(\n",
    "    mel_spec,\n",
    "    multiplier = hp.ampl_multiplier, \n",
    "    amin = hp.ampl_amin, \n",
    "    db_multiplier = hp.db_multiplier, \n",
    "    top_db = hp.max_db\n",
    "  )\n",
    "  mel_spec = mel_spec/hp.scale_db\n",
    "  return mel_spec\n",
    "\n",
    "\n",
    "def db_to_power_mel_spec(mel_spec):\n",
    "  mel_spec = mel_spec*hp.scale_db\n",
    "  mel_spec = torchaudio.functional.DB_to_amplitude(\n",
    "    mel_spec,\n",
    "    ref=hp.ampl_ref,\n",
    "    power=hp.ampl_power\n",
    "  )  \n",
    "  return mel_spec\n",
    "\n",
    "\n",
    "def convert_to_mel_spec(wav):\n",
    "  spec = spec_transform(wav)\n",
    "  mel_spec = mel_scale_transform(spec)\n",
    "  db_mel_spec = pow_to_db_mel_spec(mel_spec)\n",
    "  db_mel_spec = db_mel_spec.squeeze(0)\n",
    "  return db_mel_spec\n",
    "\n",
    "\n",
    "def inverse_mel_spec_to_wav(mel_spec):\n",
    "  power_mel_spec = db_to_power_mel_spec(mel_spec)\n",
    "  spectrogram = mel_inverse_transform(power_mel_spec)\n",
    "  pseudo_wav = griffnlim_transform(spectrogram)\n",
    "  return pseudo_wav\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   wav_path = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/LJ001-0007.wav'\n",
    "#   waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
    "#   mel_spec = convert_to_mel_spec(waveform)\n",
    "#   print(\"mel_spec:\", mel_spec.shape)\n",
    "\n",
    "#   pseudo_wav = inverse_mel_spec_to_wav(mel_spec.cuda())\n",
    "#   print(\"pseudo_wav:\", pseudo_wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:54:25.979325Z",
     "iopub.status.busy": "2025-03-18T03:54:25.978899Z",
     "iopub.status.idle": "2025-03-18T03:54:25.9885Z",
     "shell.execute_reply": "2025-03-18T03:54:25.987662Z",
     "shell.execute_reply.started": "2025-03-18T03:54:25.979295Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 12, 19, 19, 22,  3,  1, 30, 22, 25, 19, 11,  0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "symbol_to_id = {\n",
    "  s: i for i, s in enumerate(hp.symbols)\n",
    "}\n",
    "\n",
    "def text_to_seq(text):\n",
    "  text = text.lower()\n",
    "  seq = []\n",
    "  for s in text:\n",
    "    _id = symbol_to_id.get(s, None)\n",
    "    if _id is not None:\n",
    "      seq.append(_id)\n",
    "\n",
    "  seq.append(symbol_to_id[\"EOS\"])\n",
    "\n",
    "  return torch.IntTensor(seq)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(text_to_seq(\"Hello, World\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:54:28.961846Z",
     "iopub.status.busy": "2025-03-18T03:54:28.961508Z",
     "iopub.status.idle": "2025-03-18T03:54:32.073681Z",
     "shell.execute_reply": "2025-03-18T03:54:32.072806Z",
     "shell.execute_reply.started": "2025-03-18T03:54:28.961824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "\n",
    "class TextMelDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset for loading text and mel-spectrogram pairs.\n",
    "\n",
    "    This dataset loads text and audio data, converts audio to mel-spectrograms,\n",
    "    and caches the results for faster subsequent access.\n",
    "\n",
    "    Attributes:\n",
    "        df (pandas.DataFrame): DataFrame containing metadata about the dataset.\n",
    "        cache (dict): A cache to store processed items.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame containing 'wav' and 'text_norm' columns.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.cache = {}\n",
    "\n",
    "    def get_item(self, row):\n",
    "        \"\"\"\n",
    "        Process a single row of the dataset.\n",
    "\n",
    "        Args:\n",
    "            row (pandas.Series): A row from the dataset DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Processed (text, mel-spectrogram) pair.\n",
    "        \"\"\"\n",
    "        wav_id = row[\"wav\"]                  \n",
    "        wav_path = f\"{hp.wav_path}/{wav_id}.wav\"\n",
    "        text = row[\"text_norm\"]\n",
    "        text = text_to_seq(text)\n",
    "        waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
    "        assert sample_rate == hp.sr\n",
    "        mel = convert_to_mel_spec(waveform)\n",
    "        return (text, mel)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset.\n",
    "\n",
    "        This method implements caching to speed up repeated access to the same item.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Processed (text, mel-spectrogram) pair.\n",
    "        \"\"\"\n",
    "        row = self.df.iloc[index]\n",
    "        wav_id = row[\"wav\"]\n",
    "        text_mel = self.cache.get(wav_id)\n",
    "        if text_mel is None:\n",
    "            text_mel = self.get_item(row)\n",
    "            self.cache[wav_id] = text_mel\n",
    "        \n",
    "        return text_mel\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the total number of items in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "def text_mel_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for creating batches of data.\n",
    "\n",
    "    This function pads sequences to a consistent length within each batch.\n",
    "\n",
    "    Args:\n",
    "        batch (list): List of (text, mel-spectrogram) pairs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Batched and padded tensors (text, text lengths, mel-spectrograms, mel lengths, stop tokens).\n",
    "    \"\"\"\n",
    "    text_length_max = torch.tensor(\n",
    "        [text.shape[-1] for text, _ in batch], \n",
    "        dtype=torch.int32\n",
    "    ).max()\n",
    "    mel_length_max = torch.tensor(\n",
    "        [mel.shape[-1] for _, mel in batch],\n",
    "        dtype=torch.int32\n",
    "    ).max()\n",
    "    \n",
    "    text_lengths = []\n",
    "    mel_lengths = []\n",
    "    texts_padded = []\n",
    "    mels_padded = []\n",
    "    for text, mel in batch:\n",
    "        text_length = text.shape[-1]      \n",
    "        text_padded = torch.nn.functional.pad(\n",
    "            text,\n",
    "            pad=[0, text_length_max-text_length],\n",
    "            value=0\n",
    "        )\n",
    "        mel_length = mel.shape[-1]\n",
    "        mel_padded = torch.nn.functional.pad(\n",
    "            mel,\n",
    "            pad=[0, mel_length_max-mel_length],\n",
    "            value=0\n",
    "        )\n",
    "        text_lengths.append(text_length)    \n",
    "        mel_lengths.append(mel_length)    \n",
    "        texts_padded.append(text_padded)    \n",
    "        mels_padded.append(mel_padded)\n",
    "    text_lengths = torch.tensor(text_lengths, dtype=torch.int32)\n",
    "    mel_lengths = torch.tensor(mel_lengths, dtype=torch.int32)\n",
    "    texts_padded = torch.stack(texts_padded, 0)\n",
    "    mels_padded = torch.stack(mels_padded, 0).transpose(1, 2)\n",
    "    stop_token_padded = mask_from_seq_lengths(\n",
    "        mel_lengths,\n",
    "        mel_length_max\n",
    "    )\n",
    "    stop_token_padded = (~stop_token_padded).float()\n",
    "    stop_token_padded[:, -1] = 1.0\n",
    "    \n",
    "    return texts_padded, \\\n",
    "           text_lengths, \\\n",
    "           mels_padded, \\\n",
    "           mel_lengths, \\\n",
    "           stop_token_padded\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T03:54:36.901081Z",
     "iopub.status.busy": "2025-03-18T03:54:36.900771Z",
     "iopub.status.idle": "2025-03-18T03:54:36.947609Z",
     "shell.execute_reply": "2025-03-18T03:54:36.946896Z",
     "shell.execute_reply.started": "2025-03-18T03:54:36.901056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# https://github.com/NVIDIA/tacotron2/blob/master/model.py\n",
    "# https://github.com/NVIDIA/tacotron2/blob/master/layers.py\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents a single encoder block in the Transformer architecture.\n",
    "\n",
    "    This block consists of self-attention followed by a feedforward network,\n",
    "    with layer normalization and residual connections.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the EncoderBlock with its layers.\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.norm_1 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hp.embedding_size,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
    "        self.norm_2 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "        self.linear_1 = nn.Linear(hp.embedding_size, hp.dim_feedforward)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
    "        self.linear_2 = nn.Linear(hp.dim_feedforward, hp.embedding_size)\n",
    "        self.dropout_3 = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the EncoderBlock.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor\n",
    "            attn_mask (Tensor, optional): Attention mask\n",
    "            key_padding_mask (Tensor, optional): Key padding mask\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after passing through the encoder block\n",
    "        \"\"\"\n",
    "        x_out = self.norm_1(x)\n",
    "        x_out, _ = self.attn(\n",
    "            query=x_out, \n",
    "            key=x_out, \n",
    "            value=x_out,\n",
    "            attn_mask=attn_mask,\n",
    "            key_padding_mask=key_padding_mask\n",
    "        )\n",
    "        x_out = self.dropout_1(x_out)\n",
    "        x = x + x_out    \n",
    "\n",
    "        x_out = self.norm_2(x) \n",
    "        x_out = self.linear_1(x_out)\n",
    "        x_out = F.relu(x_out)\n",
    "        x_out = self.dropout_2(x_out)\n",
    "        x_out = self.linear_2(x_out)\n",
    "        x_out = self.dropout_3(x_out)\n",
    "        x = x + x_out\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents a single decoder block in the Transformer architecture.\n",
    "\n",
    "    This block consists of self-attention, encoder-decoder attention, and a feedforward network,\n",
    "    with layer normalization and residual connections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the DecoderBlock with its layers.\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm_1 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "        self.self_attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hp.embedding_size,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
    "        self.norm_2 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hp.embedding_size,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )    \n",
    "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
    "        self.norm_3 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "        self.linear_1 = nn.Linear(hp.embedding_size, hp.dim_feedforward)\n",
    "        self.dropout_3 = torch.nn.Dropout(0.1)\n",
    "        self.linear_2 = nn.Linear(hp.dim_feedforward, hp.embedding_size)\n",
    "        self.dropout_4 = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x, memory, x_attn_mask=None, x_key_padding_mask=None,\n",
    "                memory_attn_mask=None, memory_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the DecoderBlock.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor\n",
    "            memory (Tensor): Encoder output\n",
    "            x_attn_mask (Tensor, optional): Self-attention mask\n",
    "            x_key_padding_mask (Tensor, optional): Self-attention key padding mask\n",
    "            memory_attn_mask (Tensor, optional): Encoder-decoder attention mask\n",
    "            memory_key_padding_mask (Tensor, optional): Encoder-decoder key padding mask\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after passing through the decoder block\n",
    "        \"\"\"\n",
    "        x_out, _ = self.self_attn(\n",
    "            query=x, \n",
    "            key=x, \n",
    "            value=x,\n",
    "            attn_mask=x_attn_mask,\n",
    "            key_padding_mask=x_key_padding_mask\n",
    "        )\n",
    "        x_out = self.dropout_1(x_out)\n",
    "        x = self.norm_1(x + x_out)\n",
    "         \n",
    "        x_out, _ = self.attn(\n",
    "            query=x,\n",
    "            key=memory,\n",
    "            value=memory,\n",
    "            attn_mask=memory_attn_mask,\n",
    "            key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        x_out = self.dropout_2(x_out)\n",
    "        x = self.norm_2(x + x_out)\n",
    "\n",
    "        x_out = self.linear_1(x)\n",
    "        x_out = F.relu(x_out)\n",
    "        x_out = self.dropout_3(x_out)\n",
    "        x_out = self.linear_2(x_out)\n",
    "        x_out = self.dropout_4(x_out)\n",
    "        x = self.norm_3(x + x_out)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EncoderPreNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder pre-network that processes input text before the main encoder.\n",
    "\n",
    "    This network applies embedding, linear transformations, and convolutional layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the EncoderPreNet with its layers.\n",
    "        \"\"\"\n",
    "        super(EncoderPreNet, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=hp.text_num_embeddings,\n",
    "            embedding_dim=hp.encoder_embedding_size\n",
    "        )\n",
    "        self.linear_1 = nn.Linear(hp.encoder_embedding_size, hp.encoder_embedding_size)\n",
    "        self.linear_2 = nn.Linear(hp.encoder_embedding_size, hp.embedding_size)\n",
    "        self.conv_1 = nn.Conv1d(\n",
    "            hp.encoder_embedding_size, \n",
    "            hp.encoder_embedding_size,\n",
    "            kernel_size=hp.encoder_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.encoder_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_1 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
    "        self.dropout_1 = torch.nn.Dropout(0.5)\n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            hp.encoder_embedding_size, \n",
    "            hp.encoder_embedding_size,\n",
    "            kernel_size=hp.encoder_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.encoder_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_2 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.5)\n",
    "        self.conv_3 = nn.Conv1d(\n",
    "            hp.encoder_embedding_size, \n",
    "            hp.encoder_embedding_size,\n",
    "            kernel_size=hp.encoder_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.encoder_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_3 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
    "        self.dropout_3 = torch.nn.Dropout(0.5)    \n",
    "\n",
    "    def forward(self, text):\n",
    "        \"\"\"\n",
    "        Forward pass of the EncoderPreNet.\n",
    "\n",
    "        Args:\n",
    "            text (Tensor): Input text tensor\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Processed text tensor\n",
    "        \"\"\"\n",
    "        x = self.embedding(text) # (N, S, E)\n",
    "        x = self.linear_1(x)\n",
    "        x = x.transpose(2, 1) # (N, E, S) \n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)    \n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = x.transpose(1, 2) # (N, S, E)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class PostNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Post-network that refines the output of the decoder.\n",
    "\n",
    "    This network applies a series of convolutional layers to the mel spectrogram.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the PostNet with its layers.\n",
    "        \"\"\"\n",
    "        super(PostNet, self).__init__()  \n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(\n",
    "            hp.mel_freq, \n",
    "            hp.postnet_embedding_size,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_1 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
    "        self.dropout_1 = torch.nn.Dropout(0.5)\n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            hp.postnet_embedding_size, \n",
    "            hp.postnet_embedding_size,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_2 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.5)\n",
    "        self.conv_3 = nn.Conv1d(\n",
    "            hp.postnet_embedding_size, \n",
    "            hp.postnet_embedding_size,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_3 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
    "        self.dropout_3 = torch.nn.Dropout(0.5)\n",
    "        self.conv_4 = nn.Conv1d(\n",
    "            hp.postnet_embedding_size, \n",
    "            hp.postnet_embedding_size,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_4 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
    "        self.dropout_4 = torch.nn.Dropout(0.5)\n",
    "        self.conv_5 = nn.Conv1d(\n",
    "            hp.postnet_embedding_size, \n",
    "            hp.postnet_embedding_size,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_5 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
    "        self.dropout_5 = torch.nn.Dropout(0.5)\n",
    "        self.conv_6 = nn.Conv1d(\n",
    "            hp.postnet_embedding_size, \n",
    "            hp.mel_freq,\n",
    "            kernel_size=hp.postnet_kernel_size, \n",
    "            stride=1,\n",
    "            padding=int((hp.postnet_kernel_size - 1) / 2), \n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_6 = nn.BatchNorm1d(hp.mel_freq)\n",
    "        self.dropout_6 = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the PostNet.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input mel spectrogram\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Refined mel spectrogram\n",
    "        \"\"\"\n",
    "        x = x.transpose(2, 1) # (N, FREQ, TIME)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_1(x) # (N, POSNET_DIM, TIME)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_2(x) # (N, POSNET_DIM, TIME)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_3(x) # (N, POSNET_DIM, TIME)    \n",
    "        x = self.conv_4(x)\n",
    "        x = self.bn_4(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_4(x) # (N, POSNET_DIM, TIME)    \n",
    "        x = self.conv_5(x)\n",
    "        x = self.bn_5(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_5(x) # (N, POSNET_DIM, TIME)\n",
    "        x = self.conv_6(x)\n",
    "        x = self.bn_6(x)\n",
    "        x = self.dropout_6(x) # (N, FREQ, TIME)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "class DecoderPreNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder pre-network that processes mel spectrograms before the main decoder.\n",
    "\n",
    "    This network applies linear transformations with dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the DecoderPreNet with its layers.\n",
    "        \"\"\"\n",
    "        super(DecoderPreNet, self).__init__()\n",
    "        self.linear_1 = nn.Linear(hp.mel_freq, hp.embedding_size)\n",
    "        self.linear_2 = nn.Linear(hp.embedding_size, hp.embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the DecoderPreNet.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input mel spectrogram\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Processed mel spectrogram\n",
    "        \"\"\"\n",
    "        x = self.linear_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=True)\n",
    "        x = self.linear_2(x)\n",
    "        x = F.relu(x)    \n",
    "        x = F.dropout(x, p=0.5, training=True)\n",
    "        return x    \n",
    "\n",
    "class TransformerTTS(nn.Module):\n",
    "    \"\"\"\n",
    "    Main Transformer-based Text-to-Speech model.\n",
    "\n",
    "    This model combines encoder, decoder, and various auxiliary networks to generate mel spectrograms from text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        Initialize the TransformerTTS model with its components.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to run the model on\n",
    "        \"\"\"\n",
    "        super(TransformerTTS, self).__init__()\n",
    "        self.encoder_prenet = EncoderPreNet()\n",
    "        self.decoder_prenet = DecoderPreNet()\n",
    "        self.postnet = PostNet()\n",
    "        self.pos_encoding = nn.Embedding(num_embeddings=hp.max_mel_time, embedding_dim=hp.embedding_size)\n",
    "        self.encoder_block_1 = EncoderBlock()\n",
    "        self.encoder_block_2 = EncoderBlock()\n",
    "        self.encoder_block_3 = EncoderBlock()\n",
    "        self.decoder_block_1 = DecoderBlock()\n",
    "        self.decoder_block_2 = DecoderBlock()\n",
    "        self.decoder_block_3 = DecoderBlock()\n",
    "        self.linear_1 = nn.Linear(hp.embedding_size, hp.mel_freq) \n",
    "        self.linear_2 = nn.Linear(hp.embedding_size, 1)\n",
    "        self.norm_memory = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
    "\n",
    "    def forward(self, text, text_len, mel, mel_len):\n",
    "        \"\"\"\n",
    "        Forward pass of the TransformerTTS model.\n",
    "\n",
    "        Args:\n",
    "            text (Tensor): Input text tensor\n",
    "            text_len (Tensor): Lengths of input texts\n",
    "            mel (Tensor): Target mel spectrogram\n",
    "            mel_len (Tensor): Lengths of target mel spectrograms\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor, Tensor]: Predicted mel spectrogram (post-net), \n",
    "                                           predicted mel spectrogram (pre-net),\n",
    "                                           stop token predictions\n",
    "        \"\"\"\n",
    "        N = text.shape[0]\n",
    "        S = text.shape[1]\n",
    "        TIME = mel.shape[1]\n",
    "\n",
    "        # Create masks\n",
    "        self.src_key_padding_mask = torch.zeros((N, S), device=text.device).masked_fill(\n",
    "            ~mask_from_seq_lengths(text_len, max_length=S), float(\"-inf\")\n",
    "        )\n",
    "        self.src_mask = torch.zeros((S, S), device=text.device).masked_fill(\n",
    "            torch.triu(torch.full((S, S), True, dtype=torch.bool), diagonal=1).to(text.device),       \n",
    "            float(\"-inf\")\n",
    "        )\n",
    "        self.tgt_key_padding_mask = torch.zeros((N, TIME), device=mel.device).masked_fill(\n",
    "            ~mask_from_seq_lengths(mel_len, max_length=TIME), float(\"-inf\")\n",
    "        )\n",
    "        self.tgt_mask = torch.zeros((TIME, TIME), device=mel.device).masked_fill(\n",
    "            torch.triu(torch.full((TIME, TIME), True, device=mel.device, dtype=torch.bool), diagonal=1),       \n",
    "            float(\"-inf\")\n",
    "        )\n",
    "        self.memory_mask = torch.zeros((TIME, S), device=mel.device).masked_fill(\n",
    "            torch.triu(torch.full((TIME, S), True, device=mel.device, dtype=torch.bool), diagonal=1),       \n",
    "            float(\"-inf\")\n",
    "        )    \n",
    "\n",
    "        # Encoder\n",
    "        text_x = self.encoder_prenet(text)\n",
    "        pos_codes = self.pos_encoding(torch.arange(hp.max_mel_time).to(mel.device))\n",
    "        S = text_x.shape[1]\n",
    "        text_x = text_x + pos_codes[:S]\n",
    "        text_x = self.encoder_block_1(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
    "        text_x = self.encoder_block_2(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
    "        text_x = self.encoder_block_3(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
    "        text_x = self.norm_memory(text_x)\n",
    "        \n",
    "        # Decoder\n",
    "        mel_x = self.decoder_prenet(mel)\n",
    "        mel_x = mel_x + pos_codes[:TIME]\n",
    "        mel_x = self.decoder_block_1(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask, \n",
    "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
    "                                     memory_attn_mask=self.memory_mask,\n",
    "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
    "        mel_x = self.decoder_block_2(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask, \n",
    "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
    "                                     memory_attn_mask=self.memory_mask,\n",
    "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
    "        mel_x = self.decoder_block_3(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask, \n",
    "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
    "                                     memory_attn_mask=self.memory_mask,\n",
    "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
    "\n",
    "        # Output processing\n",
    "        mel_linear = self.linear_1(mel_x)\n",
    "        mel_postnet = self.postnet(mel_linear)\n",
    "        mel_postnet = mel_linear + mel_postnet\n",
    "        stop_token = self.linear_2(mel_x)\n",
    "\n",
    "        # Masking\n",
    "        bool_mel_mask = self.tgt_key_padding_mask.ne(0).unsqueeze(-1).repeat(1, 1, hp.mel_freq)\n",
    "        mel_linear = mel_linear.masked_fill(bool_mel_mask, 0)\n",
    "        mel_postnet = mel_postnet.masked_fill(bool_mel_mask, 0)\n",
    "        stop_token = stop_token.masked_fill(bool_mel_mask[:, :, 0].unsqueeze(-1), 1e3).squeeze(2)\n",
    "        \n",
    "        return mel_postnet, mel_linear, stop_token \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, text, max_length=800, stop_token_threshold=0.5, with_tqdm=True):\n",
    "        \"\"\"\n",
    "        Generate mel spectrogram from input text (inference mode).\n",
    "\n",
    "        Args:\n",
    "            text (Tensor): Input text tensor\n",
    "            max_length (int): Maximum length of generated mel spectrogram\n",
    "            stop_token_threshold (float): Threshold for stop token prediction\n",
    "            with_tqdm (bool): Whether to use tqdm progress bar\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Generated mel spectrogram, stop token predictions\n",
    "        \"\"\"\n",
    "        self.eval()    \n",
    "        self.train(False)\n",
    "        text_lengths = torch.tensor(text.shape[1]).unsqueeze(0).cuda()\n",
    "        N = 1\n",
    "        SOS = torch.zeros((N, 1, hp.mel_freq), device=\"cuda\")\n",
    "        \n",
    "        mel_padded = SOS\n",
    "        mel_lengths = torch.tensor(1).unsqueeze(0).cuda()\n",
    "        stop_token_outputs = torch.FloatTensor([]).to(text.device)\n",
    "\n",
    "        iters = tqdm(range(max_length)) if with_tqdm else range(max_length)\n",
    "\n",
    "        for _ in iters:\n",
    "            mel_postnet, mel_linear, stop_token = self(text, text_lengths, mel_padded, mel_lengths)\n",
    "            mel_padded = torch.cat([mel_padded, mel_postnet[:, -1:, :]], dim=1)\n",
    "            if torch.sigmoid(stop_token[:,-1]) > stop_token_threshold:      \n",
    "                break\n",
    "            else:\n",
    "                stop_token_outputs = torch.cat([stop_token_outputs, stop_token[:,-1:]], dim=1)\n",
    "                mel_lengths = torch.tensor(mel_padded.shape[1]).unsqueeze(0).cuda()\n",
    "\n",
    "        return mel_postnet, stop_token_outputs\n",
    "\n",
    "def test_with_dataloader():\n",
    "    \"\"\"\n",
    "    Test the TransformerTTS model using a DataLoader.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(hp.csv_path)\n",
    "    dataset = TextMelDataset(df)  \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        num_workers=1, \n",
    "        shuffle=False,\n",
    "        sampler=None, \n",
    "        batch_size=4,\n",
    "        pin_memory=True, \n",
    "        drop_last=True,       \n",
    "        collate_fn=text_mel_collate_fn\n",
    "    )\n",
    "\n",
    "    model = TransformerTTS().cuda()\n",
    "    \n",
    "    for batch in loader:\n",
    "        text_padded, text_lengths, mel_padded, mel_lengths, stop_token_padded = batch\n",
    "        text_padded = text_padded.cuda()\n",
    "        text_lengths = text_lengths.cuda()\n",
    "        mel_padded = mel_padded.cuda()\n",
    "        mel_lengths = mel_lengths.cuda()\n",
    "        stop_token_padded = stop_token_padded.cuda()    \n",
    "\n",
    "        post, mel, stop_token = model(text_padded, text_lengths, mel_padded, mel_lengths)\n",
    "        print(\"post:\", post.shape) \n",
    "        print(\"mel:\", mel.shape) \n",
    "        print(\"stop_token:\", stop_token.shape)\n",
    "        break\n",
    "\n",
    "def test_inference():\n",
    "    \"\"\"\n",
    "    Test the inference method of the TransformerTTS model.\n",
    "    \"\"\"\n",
    "    model = TransformerTTS().cuda()\n",
    "    text = text_to_seq(\"Hello, world.\").unsqueeze(0).cuda()\n",
    "    mel_postnet, stop_token = model.inference(text, stop_token_threshold=1e3)\n",
    "    print(\"mel_postnet:\", mel_postnet.shape)\n",
    "    print(\"stop_token:\", stop_token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T01:46:50.130433Z",
     "iopub.status.busy": "2025-03-11T01:46:50.129249Z",
     "iopub.status.idle": "2025-03-11T01:46:50.136777Z",
     "shell.execute_reply": "2025-03-11T01:46:50.135761Z",
     "shell.execute_reply.started": "2025-03-11T01:46:50.13039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TTSLoss(torch.nn.Module):\n",
    "    \"\"\"https://github.com/NVIDIA/tacotron2/blob/master/loss_function.py\"\"\"\n",
    "    def __init__(self):\n",
    "        super(TTSLoss, self).__init__()\n",
    "        \n",
    "        self.mse_loss = torch.nn.MSELoss()\n",
    "        self.bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        mel_postnet_out, \n",
    "        mel_out, \n",
    "        stop_token_out, \n",
    "        mel_target, \n",
    "        stop_token_target\n",
    "      ):      \n",
    "        stop_token_target = stop_token_target.view(-1, 1)\n",
    "\n",
    "        stop_token_out = stop_token_out.view(-1, 1)\n",
    "        mel_loss = self.mse_loss(mel_out, mel_target) + \\\n",
    "            self.mse_loss(mel_postnet_out, mel_target)\n",
    "\n",
    "        stop_token_loss = self.bce_loss(stop_token_out, stop_token_target) * hp.r_gate\n",
    "\n",
    "        return mel_loss + stop_token_loss\n",
    "tts_loss = TTSLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T04:06:19.911769Z",
     "iopub.status.busy": "2025-03-18T04:06:19.911181Z",
     "iopub.status.idle": "2025-03-18T04:06:25.953419Z",
     "shell.execute_reply": "2025-03-18T04:06:25.952558Z",
     "shell.execute_reply.started": "2025-03-18T04:06:19.911738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84913\\AppData\\Local\\Temp\\ipykernel_1984\\2942050373.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(train_saved_path)\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_saved_path = r\"D:\\Project\\Nhung\\1720\"\n",
    "state = torch.load(train_saved_path)\n",
    "model = TransformerTTS().cuda()\n",
    "model.load_state_dict(state[\"model\"])\n",
    "\n",
    "text = \"Programming skills open many job opportunities in the modern world.\"\n",
    "name_file = \"hello_world.mp3\"\n",
    "\n",
    "\n",
    "postnet_mel, gate = model.inference(\n",
    "  text_to_seq(text).unsqueeze(0).cuda(),\n",
    "stop_token_threshold=5e-5,\n",
    "  with_tqdm = False\n",
    ")\n",
    "audio = inverse_mel_spec_to_wav(postnet_mel.detach()[0].T)\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def write_wav(x, f=\"audio.wav\", sr=22050, normalized=True):\n",
    "    \"\"\"Save numpy array as WAV file\"\"\"\n",
    "    if normalized:\n",
    "        x = np.int16(x * 327670)  # Convert to int16 format\n",
    "    write(f, sr, x)\n",
    "\n",
    "# Ghi file\n",
    "write_wav(audio.detach().cpu().numpy(), \"output.wav\", sr=hp.sr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T15:40:34.87129Z",
     "iopub.status.busy": "2025-03-11T15:40:34.870974Z",
     "iopub.status.idle": "2025-03-11T15:40:39.805409Z",
     "shell.execute_reply": "2025-03-11T15:40:39.804516Z",
     "shell.execute_reply.started": "2025-03-11T15:40:34.871267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1159053,
     "sourceId": 1942970,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3429100,
     "sourceId": 5982931,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5322378,
     "sourceId": 8843146,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 270277,
     "modelInstanceId": 248745,
     "sourceId": 290359,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
