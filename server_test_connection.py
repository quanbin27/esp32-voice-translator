import time
import socket
import pyaudio
import wave
import speech_recognition as sr
import numpy as np
import sounddevice as sd
import matplotlib.pyplot as plt
import threading
from matplotlib.animation import FuncAnimation
from scipy.signal import butter, filtfilt
# Bi·∫øn to√†n c·ª•c
arr = np.array([])
stop = False

def play_audio_from_array(audio_array, sample_rate=16000):
    """Ph√°t l·∫°i √¢m thanh t·ª´ m·∫£ng numpy"""
    audio_data = np.array(audio_array, dtype=np.int32) 
    sd.play(audio_data, samplerate=sample_rate)
    sd.wait()

def animate(frame):
    """H√†m c·∫≠p nh·∫≠t animation"""
    global stop, arr
    if stop:
        ani.event_source.stop()
        return
    ax1.clear()
    xs = range(len(arr))
    ys = arr
    ax1.plot(xs, ys)
    # print(xs)  # Debug xem c√≥ c·∫≠p nh·∫≠t kh√¥ng

def receive_audio():
    """H√†m nh·∫≠n d·ªØ li·ªáu √¢m thanh t·ª´ socket"""
    global arr, stop

    HOST = "0.0.0.0"  # L·∫Øng nghe tr√™n t·∫•t c·∫£ c√°c IP
    PORT = 12345      # C·ªïng k·∫øt n·ªëi

    # C·∫•u h√¨nh th√¥ng s·ªë √¢m thanh
    SAMPLE_RATE = 16000        # 16 kHz
    CHANNELS = 1               # Mono
    SAMPLE_FORMAT = pyaudio.paInt32 # 16-bit PCM
    CHUNK_SIZE = 1024          # K√≠ch th∆∞·ªõc m·ªói l·∫ßn ƒë·ªçc
    WAVE_OUTPUT_FILENAME = "temp_audio.wav"

    # Kh·ªüi t·∫°o PyAudio
    p = pyaudio.PyAudio()
    stream = p.open(format=SAMPLE_FORMAT, channels=CHANNELS, rate=SAMPLE_RATE, output=True)

    # Thi·∫øt l·∫≠p socket server ƒë·ªÉ nh·∫≠n d·ªØ li·ªáu t·ª´ ESP32
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.bind((HOST, PORT))
    server.listen(1)
    print(f"\U0001F4E1 ƒêang l·∫Øng nghe tr√™n {HOST}:{PORT}...")

    conn, addr = server.accept()
    print(f"‚úÖ K·∫øt n·ªëi t·ª´ {addr}")

    start_time = time.time()
    # audio_frames = []  # L∆∞u tr·ªØ d·ªØ li·ªáu √¢m thanh
    # int_data = np.array([])

    while time.time() - start_time < 50:
    # while True:
        data = conn.recv(CHUNK_SIZE)  # Nh·∫≠n d·ªØ li·ªáu
        if not data:
            break
        
        arr = np.frombuffer(data, dtype=np.int32) 
        # print(arr)
        # int_data = np.concatenate((int_data, arr))
        stream.write(data)  # Ph√°t √¢m thanh
        # audio_frames.append(data)  # L∆∞u d·ªØ li·ªáu v√†o danh s√°ch

    stop = True  # D·ª´ng animation
    print("üîå K·∫øt th√∫c nh·∫≠n d·ªØ li·ªáu")
    # print(int_data)
    # play_audio_from_array(int_data)
    # L∆∞u √¢m thanh v√†o file WAV
    # wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
    # wf.setnchannels(CHANNELS)
    # wf.setsampwidth(p.get_sample_size(SAMPLE_FORMAT))
    # wf.setframerate(SAMPLE_RATE)
    # wf.writeframes(b''.join(audio_frames))
    # wf.close()

    # D·ªçn d·∫πp t√†i nguy√™n
    stream.stop_stream()
    stream.close()
    p.terminate()
    conn.close()
    server.close()

    # Nh·∫≠n di·ªán gi·ªçng n√≥i t·ª´ file WAV
    # recognizer = sr.Recognizer()
    # with sr.AudioFile(WAVE_OUTPUT_FILENAME) as source:
    #     print("üé§ ƒêang nh·∫≠n di·ªán gi·ªçng n√≥i...")
    #     audio_data = recognizer.record(source)
    #     try:
    #         text = recognizer.recognize_google(audio_data, language="vi-VN")
    #         print(f"üìù VƒÉn b·∫£n nh·∫≠n di·ªán: {text}")
    #     except sr.UnknownValueError:
    #         print("‚ùå Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i.")
    #     except sr.RequestError:
    #         print("‚ö†Ô∏è L·ªói k·∫øt n·ªëi ƒë·∫øn Google Speech Recognition.")

if __name__ == '__main__':
    # Kh·ªüi t·∫°o ƒë·ªì th·ªã
    fig = plt.figure()
    ax1 = fig.add_subplot(1,1,1)
    ani = FuncAnimation(fig, animate, interval=100, cache_frame_data=False)

    # Ch·∫°y lu·ªìng nh·∫≠n d·ªØ li·ªáu √¢m thanh
    thread = threading.Thread(target=receive_audio, daemon=True)
    thread.start()

    # Ch·∫°y animation trong lu·ªìng ch√≠nh
    plt.show()

    # ƒê·ª£i lu·ªìng ph·ª• ho√†n th√†nh
    thread.join()
    print("üìå Ho√†n th√†nh ch∆∞∆°ng tr√¨nh.")
